{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6814 images belonging to 7 classes.\n",
      "Found 754 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        #rotation_range=20,\n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "        brightness_range=[0.3,1.0],\n",
    "        validation_split=0.1\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "shape = (224, 224)\n",
    "\n",
    "base_dir = \"/home/otiose/repos/epita/majurca/\"\n",
    "\n",
    "data_dir = base_dir + \"top\"\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=data_dir,\n",
    "        target_size=shape,\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        directory=data_dir,\n",
    "        target_size=shape,\n",
    "        batch_size=batch_size,\n",
    "        subset=\"validation\",\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights_arr = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_generator.classes), \n",
    "    y=train_generator.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape = (shape+(3,))\n",
    "outputShape = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50, EfficientNetB0, Xception\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten, \n",
    "    Dense,\n",
    "    GlobalAveragePooling2D, \n",
    "    Dropout\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "base_model = VGG16(input_shape=inputShape, weights=\"imagenet\", include_top=False)\n",
    "\n",
    "x = base_model.get_layer('block5_conv3').output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(outputShape, activation='softmax')(x)\n",
    "\n",
    "#base_model = InceptionV3(input_shape=inputShape, weights=\"imagenet\", include_top=False)\n",
    "\n",
    "#x = base_model.output\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(1024, activation='relu')(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#x = Dense(outputShape, activation='softmax')(x)\n",
    "\n",
    "#base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"max\")\n",
    "\n",
    "#x = base_model.output\n",
    "#x = Dense(outputShape, activation='softmax')(x)\n",
    "\n",
    "#base_model = EfficientNetB0(input_shape=inputShape, weights=\"imagenet\", include_top=False)\n",
    "\n",
    "#x = base_model.output\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(1024, activation=\"relu\")(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = Dense(outputShape, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,980,935\n",
      "Trainable params: 14,980,935\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "107/107 [==============================] - 52s 428ms/step - loss: 1.8715 - accuracy: 0.2018 - val_loss: 2.0081 - val_accuracy: 0.1353\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 41s 381ms/step - loss: 1.6435 - accuracy: 0.3139 - val_loss: 1.8029 - val_accuracy: 0.2546\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 42s 395ms/step - loss: 1.4625 - accuracy: 0.3923 - val_loss: 1.8905 - val_accuracy: 0.2109\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 41s 387ms/step - loss: 1.3666 - accuracy: 0.4347 - val_loss: 2.2711 - val_accuracy: 0.2135\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 41s 386ms/step - loss: 1.2816 - accuracy: 0.4723 - val_loss: 1.9466 - val_accuracy: 0.2082\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 39s 367ms/step - loss: 1.2042 - accuracy: 0.4985 - val_loss: 1.9752 - val_accuracy: 0.2122\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 39s 364ms/step - loss: 1.1816 - accuracy: 0.5082 - val_loss: 1.7111 - val_accuracy: 0.3103\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 40s 371ms/step - loss: 1.1299 - accuracy: 0.5211 - val_loss: 1.8638 - val_accuracy: 0.2719\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 41s 382ms/step - loss: 1.0919 - accuracy: 0.5449 - val_loss: 1.7031 - val_accuracy: 0.3528\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 40s 377ms/step - loss: 1.0867 - accuracy: 0.5518 - val_loss: 1.9286 - val_accuracy: 0.2533\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import clone_model\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#optimizer = SGD(lr=0.2, momentum=0.9, decay=0.01)\n",
    "optimizer = Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "\n",
    "#model = load_model(base_dir + \"model/model-02/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "107/107 [==============================] - 55s 482ms/step - loss: 0.8204 - accuracy: 0.6644 - val_loss: 1.5468 - val_accuracy: 0.4284\n",
      "Epoch 2/300\n",
      "107/107 [==============================] - 50s 465ms/step - loss: 0.5779 - accuracy: 0.7772 - val_loss: 1.6157 - val_accuracy: 0.5066\n",
      "Epoch 3/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.4607 - accuracy: 0.8311 - val_loss: 1.3093 - val_accuracy: 0.5703\n",
      "Epoch 4/300\n",
      "107/107 [==============================] - 50s 466ms/step - loss: 0.3862 - accuracy: 0.8607 - val_loss: 0.8616 - val_accuracy: 0.6923\n",
      "Epoch 5/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.3173 - accuracy: 0.8848 - val_loss: 0.9454 - val_accuracy: 0.6883\n",
      "Epoch 6/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.2621 - accuracy: 0.9071 - val_loss: 0.9393 - val_accuracy: 0.6830\n",
      "Epoch 7/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.2373 - accuracy: 0.9159 - val_loss: 0.7531 - val_accuracy: 0.7467\n",
      "Epoch 8/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.2065 - accuracy: 0.9222 - val_loss: 0.8977 - val_accuracy: 0.7042\n",
      "Epoch 9/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.1835 - accuracy: 0.9348 - val_loss: 0.6802 - val_accuracy: 0.7825\n",
      "Epoch 10/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 0.1543 - accuracy: 0.9460 - val_loss: 0.8192 - val_accuracy: 0.7202\n",
      "Epoch 11/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.1545 - accuracy: 0.9480 - val_loss: 0.6824 - val_accuracy: 0.7719\n",
      "Epoch 12/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.1302 - accuracy: 0.9498 - val_loss: 0.5826 - val_accuracy: 0.8143\n",
      "Epoch 13/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.1174 - accuracy: 0.9554 - val_loss: 0.8162 - val_accuracy: 0.7613\n",
      "Epoch 14/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.1087 - accuracy: 0.9592 - val_loss: 0.5806 - val_accuracy: 0.8117\n",
      "Epoch 15/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 0.1068 - accuracy: 0.9592 - val_loss: 0.7173 - val_accuracy: 0.7958\n",
      "Epoch 16/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0817 - accuracy: 0.9701 - val_loss: 0.5322 - val_accuracy: 0.8355\n",
      "Epoch 17/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 0.0958 - accuracy: 0.9629 - val_loss: 0.5231 - val_accuracy: 0.8462\n",
      "Epoch 18/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0847 - accuracy: 0.9674 - val_loss: 0.4963 - val_accuracy: 0.8462\n",
      "Epoch 19/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 0.0805 - accuracy: 0.9704 - val_loss: 0.7580 - val_accuracy: 0.7918\n",
      "Epoch 20/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 0.0657 - accuracy: 0.9748 - val_loss: 0.6772 - val_accuracy: 0.8143\n",
      "Epoch 21/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0526 - accuracy: 0.9792 - val_loss: 0.5761 - val_accuracy: 0.8422\n",
      "Epoch 22/300\n",
      "107/107 [==============================] - 52s 480ms/step - loss: 0.0595 - accuracy: 0.9767 - val_loss: 0.8160 - val_accuracy: 0.7865\n",
      "Epoch 23/300\n",
      "107/107 [==============================] - 52s 479ms/step - loss: 0.0552 - accuracy: 0.9761 - val_loss: 1.0087 - val_accuracy: 0.7467\n",
      "Epoch 24/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 0.0479 - accuracy: 0.9806 - val_loss: 0.7188 - val_accuracy: 0.7865\n",
      "Epoch 25/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0533 - accuracy: 0.9809 - val_loss: 0.5102 - val_accuracy: 0.8501\n",
      "Epoch 26/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0514 - accuracy: 0.9783 - val_loss: 0.5770 - val_accuracy: 0.8422\n",
      "Epoch 27/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0343 - accuracy: 0.9874 - val_loss: 0.4904 - val_accuracy: 0.8700\n",
      "Epoch 28/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0411 - accuracy: 0.9828 - val_loss: 0.5450 - val_accuracy: 0.8674\n",
      "Epoch 29/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0308 - accuracy: 0.9874 - val_loss: 0.5837 - val_accuracy: 0.8634\n",
      "Epoch 30/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0390 - accuracy: 0.9836 - val_loss: 0.8532 - val_accuracy: 0.7772\n",
      "Epoch 31/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0372 - accuracy: 0.9862 - val_loss: 0.4774 - val_accuracy: 0.8714\n",
      "Epoch 32/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0424 - accuracy: 0.9828 - val_loss: 0.6620 - val_accuracy: 0.8488\n",
      "Epoch 33/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 0.5460 - val_accuracy: 0.8448\n",
      "Epoch 34/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0580 - accuracy: 0.9818 - val_loss: 0.6307 - val_accuracy: 0.8369\n",
      "Epoch 35/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.5073 - val_accuracy: 0.8714\n",
      "Epoch 36/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 0.5483 - val_accuracy: 0.8753\n",
      "Epoch 37/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0147 - accuracy: 0.9941 - val_loss: 0.5252 - val_accuracy: 0.8899\n",
      "Epoch 38/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.6034 - val_accuracy: 0.8687\n",
      "Epoch 39/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 0.5820 - val_accuracy: 0.8554\n",
      "Epoch 40/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.4787 - val_accuracy: 0.8926\n",
      "Epoch 41/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0345 - accuracy: 0.9897 - val_loss: 0.4716 - val_accuracy: 0.8767\n",
      "Epoch 42/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0251 - accuracy: 0.9927 - val_loss: 0.5072 - val_accuracy: 0.8700\n",
      "Epoch 43/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0151 - accuracy: 0.9940 - val_loss: 0.5161 - val_accuracy: 0.8581\n",
      "Epoch 44/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0408 - accuracy: 0.9878 - val_loss: 0.5488 - val_accuracy: 0.8607\n",
      "Epoch 45/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.5003 - val_accuracy: 0.8912\n",
      "Epoch 46/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0080 - accuracy: 0.9965 - val_loss: 0.6646 - val_accuracy: 0.8607\n",
      "Epoch 47/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0111 - accuracy: 0.9950 - val_loss: 0.5093 - val_accuracy: 0.8859\n",
      "Epoch 48/300\n",
      "107/107 [==============================] - 50s 467ms/step - loss: 0.0116 - accuracy: 0.9949 - val_loss: 0.5908 - val_accuracy: 0.8859\n",
      "Epoch 49/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0358 - accuracy: 0.9868 - val_loss: 0.5302 - val_accuracy: 0.8660\n",
      "Epoch 50/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.6051 - val_accuracy: 0.8687\n",
      "Epoch 51/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0425 - accuracy: 0.9828 - val_loss: 0.4320 - val_accuracy: 0.8939\n",
      "Epoch 52/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.4283 - val_accuracy: 0.9058\n",
      "Epoch 53/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 0.4784 - val_accuracy: 0.9019\n",
      "Epoch 54/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.4718 - val_accuracy: 0.8992\n",
      "Epoch 55/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.7412 - val_accuracy: 0.8448\n",
      "Epoch 56/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.7730 - val_accuracy: 0.8263\n",
      "Epoch 57/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0265 - accuracy: 0.9899 - val_loss: 0.7024 - val_accuracy: 0.8408\n",
      "Epoch 58/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0261 - accuracy: 0.9887 - val_loss: 0.5432 - val_accuracy: 0.8833\n",
      "Epoch 59/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.6082 - val_accuracy: 0.8621\n",
      "Epoch 60/300\n",
      "107/107 [==============================] - 50s 472ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.5300 - val_accuracy: 0.8939\n",
      "Epoch 61/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.4648 - val_accuracy: 0.9138\n",
      "Epoch 62/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0315 - accuracy: 0.9878 - val_loss: 0.5605 - val_accuracy: 0.8727\n",
      "Epoch 63/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.5477 - val_accuracy: 0.8820\n",
      "Epoch 64/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.5775 - val_accuracy: 0.8806\n",
      "Epoch 65/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.4547 - val_accuracy: 0.9098\n",
      "Epoch 66/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0374 - accuracy: 0.9899 - val_loss: 0.5247 - val_accuracy: 0.8714\n",
      "Epoch 67/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.5965 - val_accuracy: 0.8660\n",
      "Epoch 68/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0072 - accuracy: 0.9966 - val_loss: 0.5900 - val_accuracy: 0.8833\n",
      "Epoch 69/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.5730 - val_accuracy: 0.8966\n",
      "Epoch 70/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.5173 - val_accuracy: 0.8952\n",
      "Epoch 71/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.5956 - val_accuracy: 0.9005\n",
      "Epoch 72/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.5331 - val_accuracy: 0.9072\n",
      "Epoch 73/300\n",
      "107/107 [==============================] - 50s 467ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 0.5724 - val_accuracy: 0.8939\n",
      "Epoch 74/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0058 - accuracy: 0.9974 - val_loss: 0.4638 - val_accuracy: 0.9098\n",
      "Epoch 75/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0331 - accuracy: 0.9887 - val_loss: 0.4564 - val_accuracy: 0.8952\n",
      "Epoch 76/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.5323 - val_accuracy: 0.8939\n",
      "Epoch 77/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.5681 - val_accuracy: 0.8753\n",
      "Epoch 78/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.4886 - val_accuracy: 0.9005\n",
      "Epoch 79/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.5443 - val_accuracy: 0.8979\n",
      "Epoch 80/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4608 - val_accuracy: 0.9138\n",
      "Epoch 81/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0216 - accuracy: 0.9915 - val_loss: 0.5413 - val_accuracy: 0.8833\n",
      "Epoch 82/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.5173 - val_accuracy: 0.9019\n",
      "Epoch 83/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.4883 - val_accuracy: 0.9098\n",
      "Epoch 84/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.5243 - val_accuracy: 0.9151\n",
      "Epoch 85/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.7448 - val_accuracy: 0.8528\n",
      "Epoch 86/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0575 - accuracy: 0.9883 - val_loss: 0.7011 - val_accuracy: 0.8448\n",
      "Epoch 87/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0210 - accuracy: 0.9918 - val_loss: 0.4204 - val_accuracy: 0.9045\n",
      "Epoch 88/300\n",
      "107/107 [==============================] - 50s 467ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.3944 - val_accuracy: 0.9178\n",
      "Epoch 89/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.5351 - val_accuracy: 0.8939\n",
      "Epoch 90/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.5211 - val_accuracy: 0.9005\n",
      "Epoch 91/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0035 - accuracy: 0.9984 - val_loss: 0.5030 - val_accuracy: 0.9045\n",
      "Epoch 92/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0109 - accuracy: 0.9943 - val_loss: 0.5358 - val_accuracy: 0.8966\n",
      "Epoch 93/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 0.8620 - val_accuracy: 0.7971\n",
      "Epoch 94/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0188 - accuracy: 0.9928 - val_loss: 0.4312 - val_accuracy: 0.9164\n",
      "Epoch 95/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.4686 - val_accuracy: 0.9085\n",
      "Epoch 96/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.5626 - val_accuracy: 0.8833\n",
      "Epoch 97/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.5127 - val_accuracy: 0.9032\n",
      "Epoch 98/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.4728 - val_accuracy: 0.8939\n",
      "Epoch 99/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0138 - accuracy: 0.9935 - val_loss: 0.5196 - val_accuracy: 0.8873\n",
      "Epoch 100/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.4387 - val_accuracy: 0.9098\n",
      "Epoch 101/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.4973 - val_accuracy: 0.9072\n",
      "Epoch 102/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 7.1481e-04 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.9032\n",
      "Epoch 103/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 9.2530e-04 - accuracy: 0.9993 - val_loss: 0.5068 - val_accuracy: 0.9125\n",
      "Epoch 104/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.4879 - val_accuracy: 0.9164\n",
      "Epoch 105/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.5348 - val_accuracy: 0.9164\n",
      "Epoch 106/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 5.7056e-04 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.9125\n",
      "Epoch 107/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 2.6186e-04 - accuracy: 1.0000 - val_loss: 0.5511 - val_accuracy: 0.9164\n",
      "Epoch 108/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 1.1217 - val_accuracy: 0.8156\n",
      "Epoch 109/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0744 - accuracy: 0.9743 - val_loss: 0.5517 - val_accuracy: 0.8806\n",
      "Epoch 110/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.4905 - val_accuracy: 0.9072\n",
      "Epoch 111/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.7300 - val_accuracy: 0.8501\n",
      "Epoch 112/300\n",
      "107/107 [==============================] - 51s 477ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.4296 - val_accuracy: 0.9111\n",
      "Epoch 113/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.4400 - val_accuracy: 0.9085\n",
      "Epoch 114/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.5558 - val_accuracy: 0.9072\n",
      "Epoch 115/300\n",
      "107/107 [==============================] - 52s 480ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.4860 - val_accuracy: 0.8899\n",
      "Epoch 116/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.6100 - val_accuracy: 0.8992\n",
      "Epoch 117/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.5712 - val_accuracy: 0.9138\n",
      "Epoch 118/300\n",
      "107/107 [==============================] - 51s 476ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.4026 - val_accuracy: 0.9072\n",
      "Epoch 119/300\n",
      "107/107 [==============================] - 52s 479ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.5710 - val_accuracy: 0.8740\n",
      "Epoch 120/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0069 - accuracy: 0.9972 - val_loss: 0.3764 - val_accuracy: 0.9204\n",
      "Epoch 121/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.5007 - val_accuracy: 0.9125\n",
      "Epoch 122/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.4879 - val_accuracy: 0.9032\n",
      "Epoch 123/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.4937 - val_accuracy: 0.9164\n",
      "Epoch 124/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 7.3331e-04 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.9125\n",
      "Epoch 125/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 8.9373e-04 - accuracy: 0.9999 - val_loss: 0.5466 - val_accuracy: 0.9191\n",
      "Epoch 126/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 5.1223e-04 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.9151\n",
      "Epoch 127/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 6.2005e-04 - accuracy: 0.9996 - val_loss: 0.5622 - val_accuracy: 0.9032\n",
      "Epoch 128/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 0.5872 - val_accuracy: 0.8952\n",
      "Epoch 129/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0032 - accuracy: 0.9984 - val_loss: 0.5076 - val_accuracy: 0.9138\n",
      "Epoch 130/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.6272 - val_accuracy: 0.8886\n",
      "Epoch 131/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 4.3173e-04 - accuracy: 0.9999 - val_loss: 0.5590 - val_accuracy: 0.9191\n",
      "Epoch 132/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 3.6823e-04 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9297\n",
      "Epoch 133/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 2.0352e-04 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9257\n",
      "Epoch 134/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 1.6537e-04 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.9324\n",
      "Epoch 135/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 1.7189e-04 - accuracy: 1.0000 - val_loss: 0.5998 - val_accuracy: 0.9231\n",
      "Epoch 136/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0137 - accuracy: 0.9984 - val_loss: 0.7047 - val_accuracy: 0.8156\n",
      "Epoch 137/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0489 - accuracy: 0.9821 - val_loss: 0.5992 - val_accuracy: 0.8793\n",
      "Epoch 138/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.5753 - val_accuracy: 0.8767\n",
      "Epoch 139/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.6178 - val_accuracy: 0.8806\n",
      "Epoch 140/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.4829 - val_accuracy: 0.8992\n",
      "Epoch 141/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0299 - accuracy: 0.9931 - val_loss: 0.4968 - val_accuracy: 0.8992\n",
      "Epoch 142/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.5077 - val_accuracy: 0.9164\n",
      "Epoch 143/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.5337 - val_accuracy: 0.9178\n",
      "Epoch 144/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 7.0364e-04 - accuracy: 1.0000 - val_loss: 0.5718 - val_accuracy: 0.9125\n",
      "Epoch 145/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 6.5657e-04 - accuracy: 0.9999 - val_loss: 0.5321 - val_accuracy: 0.9178\n",
      "Epoch 146/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 3.3621e-04 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.9244\n",
      "Epoch 147/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 4.3787e-04 - accuracy: 1.0000 - val_loss: 0.5816 - val_accuracy: 0.9125\n",
      "Epoch 148/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 2.5418e-04 - accuracy: 1.0000 - val_loss: 0.5698 - val_accuracy: 0.9231\n",
      "Epoch 149/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 2.3580e-04 - accuracy: 1.0000 - val_loss: 0.6054 - val_accuracy: 0.9164\n",
      "Epoch 150/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 2.5512e-04 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 0.9151\n",
      "Epoch 151/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 1.9069e-04 - accuracy: 1.0000 - val_loss: 0.6272 - val_accuracy: 0.9178\n",
      "Epoch 152/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 1.2093e-04 - accuracy: 1.0000 - val_loss: 0.6321 - val_accuracy: 0.9218\n",
      "Epoch 153/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 2.3347e-04 - accuracy: 1.0000 - val_loss: 0.6672 - val_accuracy: 0.9138\n",
      "Epoch 154/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 1.6117e-04 - accuracy: 1.0000 - val_loss: 0.6741 - val_accuracy: 0.9125\n",
      "Epoch 155/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 2.3955e-04 - accuracy: 1.0000 - val_loss: 0.6849 - val_accuracy: 0.9138\n",
      "Epoch 156/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 1.3142e-04 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.9111\n",
      "Epoch 157/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.5961 - val_accuracy: 0.8806\n",
      "Epoch 158/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0141 - accuracy: 0.9944 - val_loss: 0.7388 - val_accuracy: 0.8714\n",
      "Epoch 159/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0499 - accuracy: 0.9831 - val_loss: 0.5301 - val_accuracy: 0.8780\n",
      "Epoch 160/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0099 - accuracy: 0.9953 - val_loss: 0.5019 - val_accuracy: 0.9005\n",
      "Epoch 161/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.5288 - val_accuracy: 0.9058\n",
      "Epoch 162/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.5423 - val_accuracy: 0.9111\n",
      "Epoch 163/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 8.2798e-04 - accuracy: 0.9997 - val_loss: 0.5237 - val_accuracy: 0.9125\n",
      "Epoch 164/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.5365 - val_accuracy: 0.9164\n",
      "Epoch 165/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.5617 - val_accuracy: 0.9204\n",
      "Epoch 166/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.6449 - val_accuracy: 0.8899\n",
      "Epoch 167/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0012 - accuracy: 0.9994 - val_loss: 0.5110 - val_accuracy: 0.9204\n",
      "Epoch 168/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 3.4903e-04 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.9151\n",
      "Epoch 169/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 3.9085e-04 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.9218\n",
      "Epoch 170/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 2.8658e-04 - accuracy: 0.9999 - val_loss: 0.5840 - val_accuracy: 0.9231\n",
      "Epoch 171/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0045 - accuracy: 0.9974 - val_loss: 0.9280 - val_accuracy: 0.7984\n",
      "Epoch 172/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0207 - accuracy: 0.9925 - val_loss: 0.6279 - val_accuracy: 0.8581\n",
      "Epoch 173/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0441 - accuracy: 0.9839 - val_loss: 0.4434 - val_accuracy: 0.8859\n",
      "Epoch 174/300\n",
      "107/107 [==============================] - 52s 480ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.4023 - val_accuracy: 0.9218\n",
      "Epoch 175/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.4932 - val_accuracy: 0.9098\n",
      "Epoch 176/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.5004 - val_accuracy: 0.9191\n",
      "Epoch 177/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 6.9217e-04 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9244\n",
      "Epoch 178/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 4.6090e-04 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.9231\n",
      "Epoch 179/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 2.6913e-04 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9244\n",
      "Epoch 180/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 4.6075e-04 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.9231\n",
      "Epoch 181/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 4.0865e-04 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.9244\n",
      "Epoch 182/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 1.2286e-04 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.9244\n",
      "Epoch 183/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.6005 - val_accuracy: 0.8966\n",
      "Epoch 184/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 0.0103 - accuracy: 0.9957 - val_loss: 0.4881 - val_accuracy: 0.9045\n",
      "Epoch 185/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.4476 - val_accuracy: 0.9151\n",
      "Epoch 186/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0287 - accuracy: 0.9928 - val_loss: 0.4193 - val_accuracy: 0.9164\n",
      "Epoch 187/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.5522 - val_accuracy: 0.9085\n",
      "Epoch 188/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.4810 - val_accuracy: 0.9244\n",
      "Epoch 189/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.5934 - val_accuracy: 0.9058\n",
      "Epoch 190/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.4862 - val_accuracy: 0.9125\n",
      "Epoch 191/300\n",
      "107/107 [==============================] - 51s 476ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.4493 - val_accuracy: 0.9098\n",
      "Epoch 192/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.4519 - val_accuracy: 0.9204\n",
      "Epoch 193/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 4.3790e-04 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.9164\n",
      "Epoch 194/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.5407 - val_accuracy: 0.9178\n",
      "Epoch 195/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 8.7394e-04 - accuracy: 0.9999 - val_loss: 0.5313 - val_accuracy: 0.9164\n",
      "Epoch 196/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.5149 - val_accuracy: 0.9218\n",
      "Epoch 197/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 1.1375 - val_accuracy: 0.8050\n",
      "Epoch 198/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.7161 - val_accuracy: 0.8422\n",
      "Epoch 199/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4688 - val_accuracy: 0.9204\n",
      "Epoch 200/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.7274 - val_accuracy: 0.8448\n",
      "Epoch 201/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.4867 - val_accuracy: 0.9204\n",
      "Epoch 202/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.5347 - val_accuracy: 0.9125\n",
      "Epoch 203/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 3.2776e-04 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.9204\n",
      "Epoch 204/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 7.9538e-04 - accuracy: 0.9999 - val_loss: 0.5782 - val_accuracy: 0.9178\n",
      "Epoch 205/300\n",
      "107/107 [==============================] - 50s 467ms/step - loss: 3.6078e-04 - accuracy: 0.9999 - val_loss: 0.5865 - val_accuracy: 0.9178\n",
      "Epoch 206/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 4.6448e-04 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.9138\n",
      "Epoch 207/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 3.0048e-04 - accuracy: 0.9999 - val_loss: 0.5717 - val_accuracy: 0.9138\n",
      "Epoch 208/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 1.6980e-04 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.9244\n",
      "Epoch 209/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0173 - accuracy: 0.9931 - val_loss: 0.9171 - val_accuracy: 0.7573\n",
      "Epoch 210/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.4296 - val_accuracy: 0.9058\n",
      "Epoch 211/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.4656 - val_accuracy: 0.9151\n",
      "Epoch 212/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.5225 - val_accuracy: 0.8926\n",
      "Epoch 213/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.5074 - val_accuracy: 0.9125\n",
      "Epoch 214/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.4593 - val_accuracy: 0.9138\n",
      "Epoch 215/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 7.2050e-04 - accuracy: 0.9999 - val_loss: 0.4817 - val_accuracy: 0.9218\n",
      "Epoch 216/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 2.4685e-04 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.9138\n",
      "Epoch 217/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 5.4286e-04 - accuracy: 0.9999 - val_loss: 0.5416 - val_accuracy: 0.9178\n",
      "Epoch 218/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0091 - accuracy: 0.9984 - val_loss: 0.6947 - val_accuracy: 0.8607\n",
      "Epoch 219/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.4232 - val_accuracy: 0.9058\n",
      "Epoch 220/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.5802 - val_accuracy: 0.8886\n",
      "Epoch 221/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.3764 - val_accuracy: 0.9204\n",
      "Epoch 222/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 5.2564e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9231\n",
      "Epoch 223/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 2.7383e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9191\n",
      "Epoch 224/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 1.7376e-04 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.9257\n",
      "Epoch 225/300\n",
      "107/107 [==============================] - 50s 469ms/step - loss: 1.4751e-04 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.9151\n",
      "Epoch 226/300\n",
      "107/107 [==============================] - 50s 467ms/step - loss: 2.2371e-04 - accuracy: 0.9999 - val_loss: 0.4639 - val_accuracy: 0.9297\n",
      "Epoch 227/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 1.7216e-04 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.9151\n",
      "Epoch 228/300\n",
      "107/107 [==============================] - 52s 481ms/step - loss: 7.6386e-05 - accuracy: 1.0000 - val_loss: 0.5164 - val_accuracy: 0.9218\n",
      "Epoch 229/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 9.6159e-05 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9244\n",
      "Epoch 230/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 8.1659e-05 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.9271\n",
      "Epoch 231/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 9.0430e-05 - accuracy: 1.0000 - val_loss: 0.5554 - val_accuracy: 0.9191\n",
      "Epoch 232/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 9.7354e-05 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9138\n",
      "Epoch 233/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.9596 - val_accuracy: 0.7666\n",
      "Epoch 234/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.5061 - val_accuracy: 0.8926\n",
      "Epoch 235/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0155 - accuracy: 0.9957 - val_loss: 0.7363 - val_accuracy: 0.8302\n",
      "Epoch 236/300\n",
      "107/107 [==============================] - 51s 478ms/step - loss: 0.0104 - accuracy: 0.9960 - val_loss: 0.4470 - val_accuracy: 0.9058\n",
      "Epoch 237/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.5515 - val_accuracy: 0.9058\n",
      "Epoch 238/300\n",
      "107/107 [==============================] - 52s 480ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.5289 - val_accuracy: 0.9005\n",
      "Epoch 239/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 0.5496 - val_accuracy: 0.8992\n",
      "Epoch 240/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 0.5308 - val_accuracy: 0.9058\n",
      "Epoch 241/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.5206 - val_accuracy: 0.9125\n",
      "Epoch 242/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 5.9616e-04 - accuracy: 0.9999 - val_loss: 0.4895 - val_accuracy: 0.9191\n",
      "Epoch 243/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 2.9601e-04 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.9257\n",
      "Epoch 244/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 1.3544e-04 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.9231\n",
      "Epoch 245/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 1.6468e-04 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.9164\n",
      "Epoch 246/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 1.4088e-04 - accuracy: 1.0000 - val_loss: 0.5628 - val_accuracy: 0.9151\n",
      "Epoch 247/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 1.0209e-04 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.9244\n",
      "Epoch 248/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 6.6764e-05 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.9257\n",
      "Epoch 249/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 5.7325e-05 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.9231\n",
      "Epoch 250/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 7.9685e-05 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.9271\n",
      "Epoch 251/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 1.1122e-04 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9151\n",
      "Epoch 252/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 7.0349e-05 - accuracy: 1.0000 - val_loss: 0.5988 - val_accuracy: 0.9231\n",
      "Epoch 253/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 5.2227e-05 - accuracy: 1.0000 - val_loss: 0.6030 - val_accuracy: 0.9218\n",
      "Epoch 254/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 6.7663e-05 - accuracy: 1.0000 - val_loss: 0.5418 - val_accuracy: 0.9271\n",
      "Epoch 255/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 8.9047e-05 - accuracy: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.9045\n",
      "Epoch 256/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 4.2830e-04 - accuracy: 0.9997 - val_loss: 0.5875 - val_accuracy: 0.9191\n",
      "Epoch 257/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 9.5291e-05 - accuracy: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.9164\n",
      "Epoch 258/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 6.2390e-05 - accuracy: 1.0000 - val_loss: 0.5945 - val_accuracy: 0.9125\n",
      "Epoch 259/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 1.7315e-04 - accuracy: 1.0000 - val_loss: 0.8090 - val_accuracy: 0.9005\n",
      "Epoch 260/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0389 - accuracy: 0.9840 - val_loss: 0.7862 - val_accuracy: 0.8249\n",
      "Epoch 261/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.5572 - val_accuracy: 0.9005\n",
      "Epoch 262/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.5920 - val_accuracy: 0.8979\n",
      "Epoch 263/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.2308 - val_accuracy: 0.7984\n",
      "Epoch 264/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0285 - accuracy: 0.9925 - val_loss: 0.6085 - val_accuracy: 0.8647\n",
      "Epoch 265/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.4815 - val_accuracy: 0.9191\n",
      "Epoch 266/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0024 - accuracy: 0.9985 - val_loss: 0.5247 - val_accuracy: 0.9005\n",
      "Epoch 267/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.5552 - val_accuracy: 0.9032\n",
      "Epoch 268/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 0.4515 - val_accuracy: 0.9191\n",
      "Epoch 269/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 4.5590e-04 - accuracy: 0.9999 - val_loss: 0.5041 - val_accuracy: 0.9125\n",
      "Epoch 270/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 2.1217e-04 - accuracy: 1.0000 - val_loss: 0.4789 - val_accuracy: 0.9164\n",
      "Epoch 271/300\n",
      "107/107 [==============================] - 51s 473ms/step - loss: 1.3576e-04 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.9297\n",
      "Epoch 272/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 1.5607e-04 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 0.9085\n",
      "Epoch 273/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 1.6317e-04 - accuracy: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.9204\n",
      "Epoch 274/300\n",
      "107/107 [==============================] - 51s 475ms/step - loss: 5.9852e-04 - accuracy: 0.9997 - val_loss: 0.5461 - val_accuracy: 0.9164\n",
      "Epoch 275/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 1.9582e-04 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 0.9178\n",
      "Epoch 276/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 0.0390 - accuracy: 0.9874 - val_loss: 0.6586 - val_accuracy: 0.8475\n",
      "Epoch 277/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0097 - accuracy: 0.9959 - val_loss: 0.4342 - val_accuracy: 0.9085\n",
      "Epoch 278/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.4750 - val_accuracy: 0.9085\n",
      "Epoch 279/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 8.4641e-04 - accuracy: 0.9999 - val_loss: 0.5066 - val_accuracy: 0.9138\n",
      "Epoch 280/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 4.5863e-04 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9231\n",
      "Epoch 281/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 3.8934e-04 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9191\n",
      "Epoch 282/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 2.5098e-04 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.9244\n",
      "Epoch 283/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 1.9320e-04 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.9191\n",
      "Epoch 284/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 1.5314e-04 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9284\n",
      "Epoch 285/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 2.5140e-04 - accuracy: 0.9999 - val_loss: 0.5127 - val_accuracy: 0.9191\n",
      "Epoch 286/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 1.1440e-04 - accuracy: 1.0000 - val_loss: 0.5655 - val_accuracy: 0.9204\n",
      "Epoch 287/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 1.2754e-04 - accuracy: 1.0000 - val_loss: 0.5636 - val_accuracy: 0.9231\n",
      "Epoch 288/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 1.1062e-04 - accuracy: 1.0000 - val_loss: 0.5228 - val_accuracy: 0.9310\n",
      "Epoch 289/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 9.3656e-05 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.9218\n",
      "Epoch 290/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 9.6323e-05 - accuracy: 1.0000 - val_loss: 0.5437 - val_accuracy: 0.9310\n",
      "Epoch 291/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 5.3450e-04 - accuracy: 0.9996 - val_loss: 0.5305 - val_accuracy: 0.9151\n",
      "Epoch 292/300\n",
      "107/107 [==============================] - 51s 474ms/step - loss: 9.3925e-04 - accuracy: 0.9996 - val_loss: 0.4846 - val_accuracy: 0.9218\n",
      "Epoch 293/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 9.5541e-04 - accuracy: 0.9990 - val_loss: 0.4854 - val_accuracy: 0.9218\n",
      "Epoch 294/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.5139 - val_accuracy: 0.9191\n",
      "Epoch 295/300\n",
      "107/107 [==============================] - 51s 470ms/step - loss: 1.4645e-04 - accuracy: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.9284\n",
      "Epoch 296/300\n",
      "107/107 [==============================] - 51s 469ms/step - loss: 1.5069e-04 - accuracy: 1.0000 - val_loss: 0.5842 - val_accuracy: 0.9164\n",
      "Epoch 297/300\n",
      "107/107 [==============================] - 50s 468ms/step - loss: 1.5451e-04 - accuracy: 0.9999 - val_loss: 0.5685 - val_accuracy: 0.9218\n",
      "Epoch 298/300\n",
      "107/107 [==============================] - 51s 472ms/step - loss: 7.3933e-05 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 0.9257\n",
      "Epoch 299/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 8.4942e-05 - accuracy: 1.0000 - val_loss: 0.5760 - val_accuracy: 0.9191\n",
      "Epoch 300/300\n",
      "107/107 [==============================] - 51s 471ms/step - loss: 3.4506e-05 - accuracy: 1.0000 - val_loss: 0.6332 - val_accuracy: 0.9218\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "model_dir = base_dir + \"model/\"\n",
    "\n",
    "dirlist = os.listdir(model_dir)\n",
    "dirlist.sort()\n",
    "\n",
    "if len(dirlist) == 0:\n",
    "    iteration = \"01\"\n",
    "else:\n",
    "    last_iteration = int(dirlist[-1].split(\"-\")[1])\n",
    "    iteration = \"{:02d}\".format(last_iteration + 1)\n",
    "\n",
    "save_dir = model_dir + \"model-\" + iteration + \"/\"\n",
    "os.mkdir(save_dir)\n",
    "\n",
    "save_model(model, save_dir + \"model.h5\", save_format=\"h5\")\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_csv_file = save_dir + \"history.csv\"\n",
    "\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred_prob = model.predict(validation_generator)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = validation_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                 pp       0.89      0.94      0.91        50\n",
      "pet-barquette-clair       0.76      0.93      0.84        30\n",
      "          pet-fonce       0.96      0.90      0.93       314\n",
      "         pet-opaque       0.96      0.95      0.96       152\n",
      "         pet-colore       1.00      0.94      0.97       100\n",
      "          pet-clair       0.96      0.77      0.85        30\n",
      "       pe-hd-opaque       0.73      0.94      0.82        78\n",
      "\n",
      "           accuracy                           0.92       754\n",
      "          macro avg       0.89      0.91      0.90       754\n",
      "       weighted avg       0.93      0.92      0.92       754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "target_names = [os.path.basename(path) for path in glob(data_dir + \"/*\")]\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = train_generator.class_indices.keys()\n",
    "cm = confusion_matrix(y_true, y_pred, normalize=\"true\")\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
