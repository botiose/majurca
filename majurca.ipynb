{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Majurca</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only allocate 10GB of memory on the first GPU\n",
    "#   try:\n",
    "#     tf.config.experimental.set_virtual_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)])\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Virtual devices must be set before GPUs have been initialized\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9413 images belonging to 15 classes.\n",
      "Found 1043 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "#         rotation_range=20,\n",
    "        brightness_range=[0.3,1.0],\n",
    "        validation_split=0.1\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "shape = (224, 224)\n",
    "\n",
    "base_dir = \"/home/otiose/repos/epita/majurca/\"\n",
    "\n",
    "#data_dir = base_dir + \"data\"\n",
    "data_dir = base_dir + \"subset\"\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=data_dir,\n",
    "        target_size=shape,\n",
    "        batch_size=batch_size,\n",
    "        subset=\"training\",\n",
    "        class_mode=\"categorical\")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        directory=data_dir,\n",
    "        target_size=shape,\n",
    "        batch_size=batch_size,\n",
    "        subset=\"validation\",\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights_arr = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_generator.classes), \n",
    "    y=train_generator.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape = (shape+(3,))\n",
    "outputShape = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Creating the ANN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import (\n",
    "    Flatten, \n",
    "    Dense,\n",
    "    GlobalAveragePooling2D, \n",
    "    Dropout\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "    x = base_model.get_layer('block5_conv3').output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(outputShape, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training The ANN: Transfer Learning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Frozen weight pre-training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import clone_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "148/148 [==============================] - 116s 785ms/step - loss: 2.7094 - accuracy: 0.0717 - val_loss: 2.6777 - val_accuracy: 0.0729\n",
      "Epoch 2/10\n",
      "148/148 [==============================] - 53s 360ms/step - loss: 2.6390 - accuracy: 0.1219 - val_loss: 2.6029 - val_accuracy: 0.1352\n",
      "Epoch 3/10\n",
      "148/148 [==============================] - 53s 361ms/step - loss: 2.5691 - accuracy: 0.1481 - val_loss: 2.6586 - val_accuracy: 0.0729\n",
      "Epoch 4/10\n",
      "148/148 [==============================] - 53s 361ms/step - loss: 2.4739 - accuracy: 0.1626 - val_loss: 2.4746 - val_accuracy: 0.1659\n",
      "Epoch 5/10\n",
      "148/148 [==============================] - 53s 360ms/step - loss: 2.3848 - accuracy: 0.2043 - val_loss: 2.5599 - val_accuracy: 0.1352\n",
      "Epoch 6/10\n",
      "148/148 [==============================] - 54s 368ms/step - loss: 2.3160 - accuracy: 0.2185 - val_loss: 2.4622 - val_accuracy: 0.1534\n",
      "Epoch 7/10\n",
      "148/148 [==============================] - 55s 375ms/step - loss: 2.2490 - accuracy: 0.2419 - val_loss: 2.4778 - val_accuracy: 0.1668\n",
      "Epoch 8/10\n",
      "148/148 [==============================] - 55s 375ms/step - loss: 2.2071 - accuracy: 0.2483 - val_loss: 2.4310 - val_accuracy: 0.1582\n",
      "Epoch 9/10\n",
      "148/148 [==============================] - 56s 375ms/step - loss: 2.1806 - accuracy: 0.2483 - val_loss: 2.3500 - val_accuracy: 0.2128\n",
      "Epoch 10/10\n",
      "148/148 [==============================] - 56s 376ms/step - loss: 2.1215 - accuracy: 0.2675 - val_loss: 2.3588 - val_accuracy: 0.1630\n"
     ]
    }
   ],
   "source": [
    "with mirrored_strategy.scope():\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    optimizer = Adam()\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "with mirrored_strategy.scope():\n",
    "    optimizer = Adam(lr=1e-5)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading previous model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# model = load_model(base_dir + \"model/model-02/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Unfrozen full training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "148/148 [==============================] - 157s 1s/step - loss: 1.8837 - accuracy: 0.3420 - val_loss: 2.1992 - val_accuracy: 0.2589\n",
      "Epoch 2/500\n",
      "148/148 [==============================] - 100s 675ms/step - loss: 1.6318 - accuracy: 0.4177 - val_loss: 1.7574 - val_accuracy: 0.3816\n",
      "Epoch 3/500\n",
      "148/148 [==============================] - 102s 692ms/step - loss: 1.4591 - accuracy: 0.4733 - val_loss: 1.8047 - val_accuracy: 0.3826\n",
      "Epoch 4/500\n",
      "148/148 [==============================] - 105s 709ms/step - loss: 1.3408 - accuracy: 0.4977 - val_loss: 1.6154 - val_accuracy: 0.4554\n",
      "Epoch 5/500\n",
      "  1/148 [..............................] - ETA: 0s - loss: 1.0976 - accuracy: 0.5469"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    class_weight=class_weights,\n",
    "    epochs=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving trained model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "model_dir = base_dir + \"model/\"\n",
    "\n",
    "dirlist = os.listdir(model_dir)\n",
    "if len(dirlist) == 0:\n",
    "    iteration = \"01\"\n",
    "else:\n",
    "    last_iteration = int(dirlist[-1].split(\"-\")[1])\n",
    "    iteration = \"{:02d}\".format(last_iteration + 1)\n",
    "\n",
    "save_dir = model_dir + \"model-\" + iteration + \"/\"\n",
    "os.mkdir(save_dir)\n",
    "\n",
    "save_model(model, save_dir + \"model.h5\", save_format=\"h5\")\n",
    "hist_df = pd.DataFrame(history.history) \n",
    "hist_csv_file = save_dir + \"history.csv\"\n",
    "\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred_prob = model.predict(validation_generator)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = validation_generator.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Performance analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [os.path.basename(path) for path in glob(data_dir + \"/*\")]\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = labels, columns = labels)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True,cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
